#!/usr/bin/env python3
"""
WebDAV æ•°æ®æŒä¹…åŒ–å·¥å…· (ä¿®å¤ç‰ˆ)
åŠŸèƒ½ï¼šå¤‡ä»½/æ¢å¤/è‡ªåŠ¨æ¸…ç†/å®šæ—¶ä»»åŠ¡
"""
import os
import sys
import time
import tarfile
import schedule
import logging
from datetime import datetime
from webdav3.client import Client

# é…ç½®æ—¥å¿—ï¼šè¾“å‡ºåˆ°æ ‡å‡†è¾“å‡ºï¼Œæ–¹ä¾¿ Docker logs æŸ¥çœ‹
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - [Backup] %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

class DataPersistence:
    def __init__(self):
        self.webdav_config = {
            'webdav_hostname': os.getenv('WEBDAV_URL'),
            'webdav_login': os.getenv('WEBDAV_USERNAME'),
            'webdav_password': os.getenv('WEBDAV_PASSWORD')
        }
        self.remote_dir = os.getenv('WEBDAV_BACKUP_PATH', 'cloudreve_data_backup')
        self.local_files = ['/app/cloudreve.db', '/app/conf.ini']
        self.client = None

    def connect(self):
        if not all(self.webdav_config.values()):
            logger.error("âŒ çŽ¯å¢ƒå˜é‡æœªé…ç½® (WEBDAV_URL/USERNAME/PASSWORD)ï¼Œå¤‡ä»½åŠŸèƒ½åœç”¨")
            return False
        try:
            self.client = Client(self.webdav_config)
            # æµ‹è¯•è¿žæŽ¥
            self.client.list("/")
            return True
        except Exception as e:
            logger.error(f"âŒ WebDAV è¿žæŽ¥å¤±è´¥: {e}")
            return False

    def _cleanup(self):
        """åªä¿ç•™æœ€æ–°çš„ 5 ä»½å¤‡ä»½"""
        try:
            if not self.client.check(self.remote_dir): return

            # èŽ·å–æ‰€æœ‰æ–‡ä»¶
            files = self.client.list(self.remote_dir)
            # ç­›é€‰ä»¥ data_ å¼€å¤´çš„åŽ‹ç¼©åŒ…
            backups = [f for f in files if f.startswith('data_') and f.endswith('.tar.gz')]
            # æŒ‰æ–‡ä»¶åæŽ’åº (å› ä¸ºæ–‡ä»¶ååŒ…å«æ—¶é—´æˆ³ YYYYMMDDï¼Œæ‰€ä»¥å­—ç¬¦ä¸²æŽ’åºç­‰äºŽæ—¶é—´æŽ’åº)
            backups.sort()
            
            # å¦‚æžœæ•°é‡è¶…è¿‡ 5 ä¸ª
            if len(backups) > 5:
                # è¦åˆ é™¤çš„æ˜¯ï¼šé™¤äº†æœ€åŽ 5 ä¸ªä¹‹å¤–çš„æ‰€æœ‰æ–‡ä»¶
                to_delete = backups[:-5]
                for f in to_delete:
                    remote_path = f"{self.remote_dir}/{f}"
                    self.client.clean(remote_path)
                    logger.info(f"ðŸ—‘ï¸ è‡ªåŠ¨æ¸…ç†æ—§å¤‡ä»½: {f}")
        except Exception as e:
            logger.error(f"âš ï¸ æ¸…ç†å¤±è´¥: {e}")

    def backup(self):
        """æ‰§è¡Œä¸€æ¬¡å¤‡ä»½"""
        if not self.client and not self.connect(): return
        
        try:
            if not self.client.check(self.remote_dir):
                self.client.mkdir(self.remote_dir)

            if not os.path.exists('/app/cloudreve.db'):
                logger.warning("âš ï¸ æœ¬åœ°æ•°æ®åº“ä¸å­˜åœ¨ï¼Œè·³è¿‡å¤‡ä»½")
                return

            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            tar_name = f"/tmp/data_{timestamp}.tar.gz"
            
            # æ‰“åŒ…
            with tarfile.open(tar_name, "w:gz") as tar:
                for f in self.local_files:
                    if os.path.exists(f):
                        tar.add(f, arcname=os.path.basename(f))
            
            # ä¸Šä¼ 
            remote_path = f"{self.remote_dir}/{os.path.basename(tar_name)}"
            self.client.upload_sync(remote_path=remote_path, local_path=tar_name)
            logger.info(f"âœ… å¤‡ä»½æˆåŠŸ: {os.path.basename(tar_name)}")
            
            os.remove(tar_name)
            
            # æ‰§è¡Œæ¸…ç†
            self._cleanup()
            
        except Exception as e:
            logger.error(f"âŒ å¤‡ä»½å‡ºé”™: {e}")

    def restore(self):
        """å¯åŠ¨æ—¶æ¢å¤"""
        if not self.client and not self.connect(): return

        try:
            if not self.client.check(self.remote_dir):
                logger.info("â„¹ï¸ è¿œç¨‹å¤‡ä»½ç›®å½•ä¸å­˜åœ¨ï¼Œå°†åˆå§‹åŒ–å…¨æ–°çŽ¯å¢ƒ")
                return

            files = self.client.list(self.remote_dir)
            backups = sorted([f for f in files if f.startswith('data_') and f.endswith('.tar.gz')])
            
            if not backups:
                logger.info("â„¹ï¸ æœªæ‰¾åˆ°åŽ†å²å¤‡ä»½ï¼Œå°†åˆå§‹åŒ–å…¨æ–°çŽ¯å¢ƒ")
                return

            latest = backups[-1]
            logger.info(f"â¬‡ï¸ æ­£åœ¨æ¢å¤æœ€è¿‘çš„å¤‡ä»½: {latest}")
            
            local_path = f"/tmp/{latest}"
            self.client.download_sync(remote_path=f"{self.remote_dir}/{latest}", local_path=local_path)
            
            with tarfile.open(local_path, "r:gz") as tar:
                tar.extractall(path="/app")
            
            os.remove(local_path)
            logger.info("âœ… æ•°æ®æ¢å¤å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ¢å¤å¤±è´¥: {e}")

    def start_daemon(self):
        """å®šæ—¶ä»»åŠ¡å®ˆæŠ¤è¿›ç¨‹"""
        if not self.client and not self.connect(): return

        # èŽ·å–é—´éš”æ—¶é—´ï¼Œé»˜è®¤ 60 åˆ†é’Ÿ
        try:
            interval = int(os.getenv('SYNC_INTERVAL', '60'))
        except:
            interval = 60
            
        logger.info(f"â° å¤‡ä»½å®ˆæŠ¤è¿›ç¨‹å·²å¯åŠ¨ï¼Œé—´éš”: {interval} åˆ†é’Ÿ")
        
        # ç«‹å³æ‰§è¡Œä¸€æ¬¡å¤‡ä»½(ç”¨äºŽä¿å­˜åˆšåˆšåˆå§‹åŒ–çš„çŠ¶æ€)
        logger.info("âš¡ æ‰§è¡Œå¯åŠ¨åŽé¦–æ¬¡å¤‡ä»½...")
        self.backup()
        
        schedule.every(interval).minutes.do(self.backup)
        
        while True:
            schedule.run_pending()
            time.sleep(60) # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡ä»»åŠ¡

if __name__ == '__main__':
    agent = DataPersistence()
    
    if len(sys.argv) > 1:
        if sys.argv[1] == 'restore':
            agent.restore()
        elif sys.argv[1] == 'run':
            agent.start_daemon()
    else:
        print("Args: restore | run")
