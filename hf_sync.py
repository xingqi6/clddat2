#!/usr/bin/env python3
"""
è¶…å¤§æ–‡ä»¶åŒæ­¥å¼•æ“ (Huge File Sync)
ç‰¹ç‚¹ï¼šæµå¼ä¸Šä¼ ä¸çˆ†å†…å­˜ï¼Œä¸Šä¼ åè‡ªåŠ¨æ¸…ç†é˜²çˆ†ç¡¬ç›˜
"""
import os
import time
import logging
from huggingface_hub import HfApi, create_repo

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

class HugeFileSync:
    def __init__(self):
        self.hf_token = os.getenv('HF_TOKEN')
        self.dataset_repo = os.getenv('HF_DATASET_REPO', 'large-storage')
        self.local_path = "/app/uploads"
        
        if not self.hf_token:
            logger.error("âŒ æœªè®¾ç½® HF_TOKEN ç¯å¢ƒå˜é‡ï¼Œæ— æ³•åŒæ­¥")
            return
            
        self.api = HfApi(token=self.hf_token)
        self._init_repo()
        
        # å¿½ç•¥çš„ä¸´æ—¶æ–‡ä»¶åç¼€
        self.ignore_exts = ['.tmp', '.upload', '.part']

    def _init_repo(self):
        try:
            user = self.api.whoami()['name']
            self.full_repo = f"{user}/{self.dataset_repo}"
            create_repo(
                self.full_repo, 
                repo_type="dataset", 
                private=True, 
                exist_ok=True, 
                token=self.hf_token
            )
            logger.info(f"âœ… ä»“åº“è¿æ¥æˆåŠŸ: {self.full_repo}")
        except Exception as e:
            logger.error(f"âŒ ä»“åº“åˆå§‹åŒ–å¤±è´¥: {e}")

    def is_file_stable(self, file_path):
        """ç¡®ä¿æ–‡ä»¶ä¸æ˜¯æ­£åœ¨è¢« Cloudreve å†™å…¥ä¸­"""
        try:
            size1 = os.path.getsize(file_path)
            mtime1 = os.path.getmtime(file_path)
            # ç­‰å¾…10ç§’æ£€æµ‹å˜åŒ–
            time.sleep(10)
            size2 = os.path.getsize(file_path)
            mtime2 = os.path.getmtime(file_path)
            
            # åªæœ‰å¤§å°ä¸ä¸º0ï¼Œä¸”10ç§’å†…å®Œå…¨æ— å˜åŒ–ï¼Œæ‰è®¤ä¸ºä¸Šä¼ å®Œæˆ
            return size2 > 0 and size1 == size2 and mtime1 == mtime2
        except:
            return False

    def upload_worker(self):
        if not self.hf_token: return
        logger.info(f"ğŸš€ å¼€å§‹ç›‘æ§: {self.local_path}")
        
        while True:
            processed = False
            for root, dirs, files in os.walk(self.local_path):
                for file in files:
                    file_path = os.path.join(root, file)
                    
                    if file.startswith('.') or any(file.endswith(e) for e in self.ignore_exts):
                        continue
                    
                    if not self.is_file_stable(file_path):
                        continue
                        
                    rel_path = os.path.relpath(file_path, self.local_path)
                    gb_size = os.path.getsize(file_path) / (1024**3)
                    
                    logger.info(f"ğŸ“¦ å‘ç°æ–°æ–‡ä»¶: {rel_path} ({gb_size:.2f} GB)")
                    
                    try:
                        logger.info(f"â¬†ï¸ å¼€å§‹æµå¼ä¸Šä¼ : {rel_path} ...")
                        # å…³é”®ï¼špath_or_fileobj=file_path è§¦å‘æµå¼ä¼ è¾“
                        self.api.upload_file(
                            path_or_fileobj=file_path,
                            path_in_repo=f"uploads/{rel_path}",
                            repo_id=self.full_repo,
                            repo_type="dataset",
                            token=self.hf_token
                        )
                        logger.info(f"âœ… ä¸Šä¼ æˆåŠŸ: {rel_path}")
                        
                        # å…³é”®ï¼šåˆ é™¤æœ¬åœ°æ–‡ä»¶é‡Šæ”¾ç£ç›˜
                        os.remove(file_path)
                        logger.info(f"ğŸ—‘ï¸ å·²æ¸…ç†é‡Šæ”¾ç©ºé—´: {rel_path}")
                        processed = True
                    except Exception as e:
                        logger.error(f"âŒ ä¸Šä¼ å¤±è´¥: {e}")
                        time.sleep(10)
            
            if not processed:
                time.sleep(10)

if __name__ == '__main__':
    HugeFileSync().upload_worker()
